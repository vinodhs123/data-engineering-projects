{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "de3320d7-fe4f-4bd7-9f7d-d563f0b6b085",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "def replace_keys(data, key_mapping):\n",
    "    \"\"\"Recursively replace keys in a nested JSON structure using key_mapping.\"\"\"\n",
    "    if isinstance(data, dict):\n",
    "        new_data = {}\n",
    "        for key, value in data.items():\n",
    "            new_key = key_mapping.get(key, key)\n",
    "            if isinstance(value, dict):\n",
    "                new_data[new_key] = replace_keys(value, key_mapping)\n",
    "            elif isinstance(value, list):\n",
    "                new_data[new_key] = [replace_keys(item, key_mapping) if isinstance(item, dict) else item for item in value]\n",
    "            else:\n",
    "                new_data[new_key] = value\n",
    "        return new_data\n",
    "    return data\n",
    "\n",
    "def remove_file_path(data, keys_names):\n",
    "    \"\"\"\n",
    "    Recursively remove file paths for specified keys by keeping only the basename.\n",
    "    \"\"\"\n",
    "    if isinstance(data, dict):\n",
    "        for key, value in data.items():\n",
    "            if key in keys_names and isinstance(value, str):\n",
    "                data[key] = os.path.basename(value)\n",
    "            elif isinstance(value, dict):\n",
    "                remove_file_path(value, keys_names)\n",
    "            elif isinstance(value, list):\n",
    "                for item in value:\n",
    "                    if isinstance(item, dict):\n",
    "                        remove_file_path(item, keys_names)\n",
    "    elif isinstance(data, list):\n",
    "        for item in data:\n",
    "            if isinstance(item, dict):\n",
    "                remove_file_path(item, keys_names)\n",
    "    return data\n",
    "\n",
    "def prefix_folder_path(data, folder_path,table_name):\n",
    "    \"\"\"\n",
    "    Recursively prefix folder paths for specified keys in a nested JSON structure.\n",
    "    \"\"\"\n",
    "    if isinstance(data, dict):\n",
    "        for key, value in data.items():\n",
    "            if key in folder_path and isinstance(value, str):\n",
    "                #print(data)\n",
    "                data[key] = os.path.join(folder_path[key],table_name)\n",
    "            elif isinstance(value, dict):\n",
    "                prefix_folder_path(value, folder_path,table_name)\n",
    "            elif isinstance(value, list):\n",
    "                for item in value:\n",
    "                    if isinstance(item, dict):\n",
    "                        prefix_folder_path(item, folder_path,table_name)\n",
    "    elif isinstance(data, list):\n",
    "        for item in data:\n",
    "            if isinstance(item, dict):\n",
    "                prefix_folder_path(item, folder_path,table_name)\n",
    "    return data\n",
    "\n",
    "def correct_onboard_json(volume_path):\n",
    "    combined_json = []\n",
    "    keys_to_modify = [\"source_path_dev\", \"bronze_table_path_dev\", \"bronze_data_quality_expectations_json_dev\", \"bronze_data_quality_expectations_json_prod\", \"bronze_table_path_prod\", \"bronze_table_path_dev\", \"bronze_quarantine_table_path_prod\", \"bronze_quarantine_table_path_dev\",\"silver_table_path_dev\"]\n",
    "\n",
    "    key_mapping = {\"bronze_database_dev\": f\"bronze_database_{dbutils.widgets.get('environment')}\", \"silver_database_dev\": f\"silver_database_{dbutils.widgets.get('environment')}\", \"silver_transformation_json_dev\": f\"silver_transformation_json_{dbutils.widgets.get('environment')}\",\"source_path_dev\": f\"source_path_{dbutils.widgets.get('environment')}\",\"bronze_database_quarantine_dev\": f\"bronze_database_quarantine_{dbutils.widgets.get('environment')}\",\"silver_table_path_dev\": f\"silver_table_path_{dbutils.widgets.get('environment')}\"}\n",
    "    \n",
    "    folder_path = {f\"source_path_{dbutils.widgets.get('environment')}\": dbutils.widgets.get(\"source_path_dev\"),\n",
    "               \"bronze_table_path_dev\":dbutils.widgets.get(\"bronze_table_path_dev\"), \n",
    "               #\"source_schema_path\":dbutils.widgets.get(\"source_schema_path\"), \n",
    "               f\"silver_table_path_{dbutils.widgets.get('environment')}\":dbutils.widgets.get(\"silver_table_path_dev\"),\n",
    "               \"filestore\":dbutils.widgets.get(\"filestore\"),\n",
    "               \"DDL_file_path\":dbutils.widgets.get(\"DDL_file_path\"),\n",
    "               f\"bronze_database_{dbutils.widgets.get('environment')}\":dbutils.widgets.get(\"bronze_database\"),\n",
    "               \"bronze_data_quality_expectations_json_dev\":dbutils.widgets.get(\"bronze_data_quality_expectations_json_dev\"),\n",
    "               \"bronze_data_quality_expectations_json_prod\": dbutils.widgets.get(\"bronze_data_quality_expectations_json_prod\"),\n",
    "               \"bronze_table_path_prod\":dbutils.widgets.get(\"bronze_table_path_prod\"),\n",
    "               \"bronze_quarantine_table_path_prod\": dbutils.widgets.get(\"bronze_quarantine_table_path_prod\"),\n",
    "               \"bronze_quarantine_table_path_dev\": dbutils.widgets.get(\"bronze_quarantine_table_path_dev\")\n",
    "               #\"silver_transformation_json_dev\" : dbutils.widgets.get(\"silver_transformation_json_dev\")               \n",
    "               }\n",
    "\n",
    "\n",
    "    for file_name in os.listdir(volume_path):\n",
    "        if file_name.endswith('.json'):\n",
    "            with open(os.path.join(volume_path,file_name)) as json_file:\n",
    "                data = json.load(json_file)\n",
    "                # data = [{key_mapping.get(k, k): v for k, v in item.items()} for item in data]\n",
    "                data = [replace_keys(item, key_mapping) for item in data]\n",
    "                corrected_data = remove_file_path(data[0],keys_to_modify)\n",
    "                table_name = os.path.basename(corrected_data['source_details'][f'source_path_{dbutils.widgets.get(\"environment\")}'])\n",
    "                prefix_path = prefix_folder_path(corrected_data,folder_path,table_name)\n",
    "                combined_json.append(prefix_path)\n",
    "    \n",
    "    return combined_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "527a0296-ce99-495a-a6ed-cf794ffeb58d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "combined_json = correct_onboard_json(os.path.join(dbutils.widgets.get(\"volume_path\"), dbutils.widgets.get(\"bronze_database\")))\n",
    "\n",
    "with open(os.path.join(dbutils.widgets.get(\"volume_path\"),dbutils.widgets.get(\"combined_json_file_name\")), 'w') as outfile:\n",
    "    json.dump(combined_json, outfile)\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "prepare_onboarding_json",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
